{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import openai\n",
    "import pandas as pd\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.base import Chain\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.chains import RetrievalQA, load_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from giskard import Dataset, Model, scan, GiskardClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"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\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "# Display options.\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPCC_REPORT_URL = \"https://www.ipcc.ch/report/ar6/syr/downloads/report/IPCC_AR6_SYR_LongerReport.pdf\"\n",
    "\n",
    "LLM_NAME = \"gpt-3.5-turbo\"\n",
    "\n",
    "TEXT_COLUMN_NAME = \"query\"\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"You are the Climate Assistant, a helpful AI assistant made by Giskard.\n",
    "Your task is to answer common questions on climate change.\n",
    "You will be given a question and relevant excerpts from the IPCC Climate Change Synthesis Report (2023).\n",
    "Please provide short and clear answers based on the provided context. Be polite and helpful.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Your answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_storage() -> FAISS:\n",
    "    \"\"\"Initialize a vector storage of embedded IPCC report chunks (context).\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100, add_start_index=True)\n",
    "    docs = PyPDFLoader(IPCC_REPORT_URL).load_and_split(text_splitter)\n",
    "    db = FAISS.from_documents(docs, OpenAIEmbeddings())\n",
    "    return db\n",
    "\n",
    "\n",
    "# Create the chain.\n",
    "llm = OpenAI(temperature=0)\n",
    "prompt = PromptTemplate(template=PROMPT_TEMPLATE, input_variables=[\"question\", \"context\"])\n",
    "climate_qa_chain = RetrievalQA.from_llm(llm=llm, retriever=get_context_storage().as_retriever(), prompt=prompt)\n",
    "\n",
    "# Test the chain.\n",
    "climate_qa_chain(\"Is sea level rise avoidable? When will it stop?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom Giskard model wrapper for the serialization.\n",
    "class FAISSRAGModel(Model):\n",
    "    def model_predict(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        return df[TEXT_COLUMN_NAME].apply(lambda x: self.model.run({\"query\": x}))\n",
    "\n",
    "    def save_model(self, path: str):\n",
    "        out_dest = Path(path)\n",
    "        # Save the chain object\n",
    "        self.model.save(out_dest.joinpath(\"model.json\"))\n",
    "\n",
    "        # Save the FAISS-based retriever\n",
    "        db = self.model.retriever.vectorstore\n",
    "        db.save_local(out_dest.joinpath(\"faiss\"))\n",
    "\n",
    "    @classmethod\n",
    "    def load_model(cls, path: str) -> Chain:\n",
    "        src = Path(path)\n",
    "\n",
    "        # Load the FAISS-based retriever\n",
    "        db = FAISS.load_local(src.joinpath(\"faiss\"), OpenAIEmbeddings())\n",
    "\n",
    "        # Load the chain, passing the retriever\n",
    "        chain = load_chain(src.joinpath(\"model.json\"), retriever=db.as_retriever())\n",
    "        return chain\n",
    "\n",
    "\n",
    "# Wrap the QA chain\n",
    "giskard_model = FAISSRAGModel(\n",
    "    model=climate_qa_chain,  # A prediction function that encapsulates all the data pre-processing steps and that could be executed with the dataset used by the scan.\n",
    "    model_type=\"text_generation\",  # Either regression, classification or text_generation.\n",
    "    name=\"Climate Change Question Answering\",  # Optional.\n",
    "    description=\"This model answers any question about climate change based on IPCC reports\",  # Is used to generate prompts during the scan.\n",
    "    feature_names=[TEXT_COLUMN_NAME]  # Default: all columns of your dataset.\n",
    ")\n",
    "\n",
    "# Optional: Wrap a dataframe of sample input prompts to validate the model wrapping and to narrow specific tests' queries.\n",
    "giskard_dataset = Dataset(pd.DataFrame({\n",
    "    TEXT_COLUMN_NAME: [\n",
    "        \"According to the IPCC report, what are key risks in the Europe?\",\n",
    "        \"Is sea level rise avoidable? When will it stop?\"\n",
    "    ]\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(giskard_model.predict(giskard_dataset).prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results = scan(giskard_model, giskard_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(full_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results.to_html(\"LLM_reports.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_suite = full_results.generate_test_suite(\"Test suite generated by scan\")\n",
    "test_suite.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
